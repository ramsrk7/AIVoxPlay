<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Realtime Voice Agent</title>

<!--  ――  DESIGN ――――――――――――――――――――――――――――――――――― -->
<style>
  :root {
    --clr-accent : #22c55e;            /* green while listening  */
    --clr-play   : #7c3aed;            /* purple while playing   */
    --clr-play2  : #c084fc;            /* lighter pulse purple    */
    --clr-bg     : #f5f7fa;
    --clr-card   : #ffffff;
    --radius     : 14px;
    --shadow     : 0 8px 20px rgba(0,0,0,.08);
    --font-main  : 'Inter', system-ui, sans-serif;
  }

  *{ box-sizing:border-box; }

  body{
    min-height:100vh;
    display:flex; flex-direction:column; align-items:center;
    padding:2.5rem 1rem; background:var(--clr-bg);
    font-family:var(--font-main); color:#333;
  }

  /* ---------- INDICATOR ---------- */
  #indicator{
    width:90px; height:90px; border-radius:50%;
    background:var(--clr-accent); box-shadow:0 0 0 0 var(--clr-accent);
    margin-bottom:1.5rem; transition:background .3s;
  }
  .listening{
    animation:bounce .5s infinite alternate,
              glow-listen 1s infinite;
  }
  .playing{
    animation:pulse-size 1.2s infinite ease-in-out,
              glow-play   1.2s infinite ease-in-out,
              pulse-color 1.2s infinite ease-in-out;
  }

  /* keyframes */
  @keyframes bounce       { to   { transform:translateY(-28px);} }
  @keyframes pulse-size   { 0%,100%{transform:scale(1);} 50%{transform:scale(1.2);} }
  @keyframes pulse-color  { 0%,100%{background:var(--clr-play);}
                            50%    {background:var(--clr-play2);} }
  @keyframes glow-listen  { 0%{box-shadow:0 0 0 0 rgba(34,197,94,.7);}
                            100%{box-shadow:0 0 16px 12px rgba(34,197,94,0);} }
  @keyframes glow-play    { 0%{box-shadow:0 0 0 0 rgba(124,58,237,.7);}
                            100%{box-shadow:0 0 16px 12px rgba(124,58,237,0);} }

  /* ---------- BUTTONS ---------- */
  .btn{
    padding:.75rem 1.5rem; margin:.5rem; font-size:1rem; font-weight:600;
    border:none; border-radius:var(--radius); background:var(--clr-accent);
    color:#fff; cursor:pointer; transition:transform .15s, background .25s;
    box-shadow:var(--shadow);
  }
  .btn:disabled{ background:#c4c4c4; cursor:not-allowed; box-shadow:none; }
  .btn:not(:disabled):hover{ transform:translateY(-2px); }

  /* ---------- TRANSCRIPT ---------- */
  #transcript-card{
    margin-top:2rem; width:100%; max-width:680px;
    background:var(--clr-card); border-radius:var(--radius); box-shadow:var(--shadow);
    padding:1rem 1.25rem; overflow-y:auto; height:220px;
  }
  #transcript-list{ list-style:none; margin:0; padding:0; }
  #transcript-list li{
    padding:.4rem 0; border-bottom:1px solid #ececec;
    font-size:1.05rem; line-height:1.4;
  }
  #transcript-list li:last-child{ border-bottom:none; }
</style>

<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap" rel="stylesheet">
</head>
<body>

<div id="indicator"></div>

<div>
  <button id="startBtn" class="btn">Start</button>
  <button id="stopBtn"  class="btn" disabled>Stop</button>
</div>

<div id="transcript-card">
  <ul id="transcript-list">
    <li style="opacity:.6">Transcript will appear here…</li>
  </ul>
</div>

<!--  ――  LOGIC ――――――――――――――――――――――――――――――――――― -->
<script>
  /* CONFIG */
  const CLIENT_ID  = crypto.randomUUID();  // generate a unique ID per session
  const SR         = 24000;                // must match server sample rate
  const VAD_THRESH = 0.02;
  const WS_IN  = `ws://localhost:8000/audio/in/${CLIENT_ID}`;
  const WS_OUT = `ws://localhost:8000/audio/out/${CLIENT_ID}`;
  
  /* DOM refs */
  const indicator = document.getElementById('indicator');
  const startBtn  = document.getElementById('startBtn');
  const stopBtn   = document.getElementById('stopBtn');
  const transcriptList = document.getElementById('transcript-list');
  
  /* State */
  let wsIn, wsOut, audioCtx, source, processor;
  let listening = false, playing = false;
  let playCursor = 0;
  let micBuffer = [];
  let activeSources = [];
  
  /* ---------- BUTTONS ---------- */
  startBtn.onclick = () => { startBtn.disabled=true; stopBtn.disabled=false; init(); };
  stopBtn.onclick  = () => { stopBtn.disabled=true;  startBtn.disabled=false; cleanup(); };
  
  /* ---------- INIT ---------- */
  function init() {
    wsIn = new WebSocket(WS_IN);
    wsOut = new WebSocket(WS_OUT);
    wsIn.onopen = onWsInOpen;
    wsOut.onmessage = onWsOutMessage;
    wsOut.binaryType = "arraybuffer";
  }
  
  /* ---------- Mic Audio Stream ---------- */
  function onWsInOpen() {
    listening = true;
    audioCtx = new AudioContext({ sampleRate: SR });
  
    navigator.mediaDevices.getUserMedia({ audio: true }).then(stream => {
      source = audioCtx.createMediaStreamSource(stream);
      processor = audioCtx.createScriptProcessor(4096, 1, 1);
      source.connect(processor);
      processor.connect(audioCtx.destination);
      processor.onaudioprocess = handleMic;
    }).catch(err => console.error("Mic error:", err));
  }
  
  function handleMic(e) {
    const data = e.inputBuffer.getChannelData(0);
    const rms = Math.sqrt(data.reduce((s, v) => s + v * v, 0) / data.length);
  
    // visual indicator
    if (rms > VAD_THRESH && listening) indicator.classList.add("listening");
    else                               indicator.classList.remove("listening");
  
    // float32 to int16
    const pcm16 = new Int16Array(data.length);
    for (let i = 0; i < data.length; i++) {
      const s = Math.max(-1, Math.min(1, data[i]));
      pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7fff;
    }
  
    if (playing && rms > VAD_THRESH) {
      cancelPlayback();
      wsIn.send(JSON.stringify({ type: "cancel_audio" }));
      playing = false;
      listening = true;
      indicator.classList.remove("playing");
      indicator.classList.add("listening");
  
      micBuffer.forEach(buf => {
        wsIn.send(JSON.stringify({
          type: "input_audio_buffer.append",
          audio: btoa(String.fromCharCode(...new Uint8Array(buf)))
        }));
      });
      micBuffer.length = 0;
    }
  
    if (listening) {
      wsIn.send(JSON.stringify({
        type: "input_audio_buffer.append",
        audio: btoa(String.fromCharCode(...new Uint8Array(pcm16.buffer)))
      }));
    } else {
      micBuffer.push(pcm16.buffer);
    }
  }
  
  /* ---------- WebSocket OUT ---------- */
  function onWsOutMessage(evt) {
    if (typeof evt.data === "string") {
      const msg = JSON.parse(evt.data);
  
      if (msg.type === "transcript") addTranscript(msg.text);
      if (msg.type === "audio.cancelled") {
        cancelPlayback(); playing = false; listening = true;
        indicator.classList.remove("playing");
      }
      if (msg.type === "audio.complete") {
        playing = false; listening = true;
        indicator.classList.remove("playing");
      }
      return;
    }
  
    if (!playing) {
      playing = true;
      listening = false;
      indicator.classList.remove("listening");
      indicator.classList.add("playing");
    }
  
    playPcmInt16(evt.data);
  }
  
  /* ---------- Playback & UI ---------- */
  function addTranscript(text) {
    if (transcriptList.firstElementChild?.style.opacity) transcriptList.innerHTML = "";
    const li = document.createElement("li");
    li.textContent = text;
    transcriptList.appendChild(li);
    transcriptList.scrollTop = transcriptList.scrollHeight;
  }
  
  function playPcmInt16(buf) {
    const i16 = new Int16Array(buf);
    const f32 = new Float32Array(i16.length);
    for (let i = 0; i < i16.length; i++) f32[i] = i16[i] / 0x8000;
  
    const audioBuffer = audioCtx.createBuffer(1, f32.length, SR);
    audioBuffer.getChannelData(0).set(f32);
  
    const src = audioCtx.createBufferSource();
    const gain = audioCtx.createGain();
    gain.gain.value = 0;
    src.buffer = audioBuffer;
    src.connect(gain).connect(audioCtx.destination);
  
    const startAt = Math.max(playCursor, audioCtx.currentTime + 0.01);
    const fadeTime = 0.005;
    gain.gain.setValueAtTime(0, startAt);
    gain.gain.linearRampToValueAtTime(1, startAt + fadeTime);
  
    src.start(startAt);
    playCursor = startAt + audioBuffer.duration;
  
    activeSources.push(src);
    src.onended = () => {
      activeSources = activeSources.filter(s => s !== src);
      if (!playing) indicator.classList.remove("playing");
    };
  }
  
  function cancelPlayback() {
    activeSources.forEach(s => { try { s.stop(); } catch (e) {} });
    activeSources.length = 0;
    playCursor = audioCtx.currentTime;
  }
  
  /* ---------- Cleanup ---------- */
  function cleanup() {
    cancelPlayback();
    processor?.disconnect();
    source?.disconnect();
    audioCtx?.close();
    wsIn?.close();
    wsOut?.close();
    listening = playing = false;
    indicator.classList.remove("listening", "playing");
    playCursor = 0;
    micBuffer.length = 0;
  }
</script>
  
</body>
</html>
